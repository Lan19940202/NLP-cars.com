{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(url):\n",
    "    car_url=requests.get(url)\n",
    "    while str(car_url) == '<Response [503]>':\n",
    "        url = next_page(url)\n",
    "        car_url=requests.get(url)\n",
    "    return car_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrap_rate2(url):\n",
    "    #car_url=requests.get(url)\n",
    "    car_url = test(url)\n",
    "    car_soup = bs4.BeautifulSoup(car_url.text,'lxml')\n",
    "    #get rate\n",
    "    rate_all = car_soup.select('article cars-star-rating')\n",
    "    stars=[i.text[0] for i in rate_all[0::7]]\n",
    "    return stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrap_rate(url):\n",
    "    #get rate\n",
    "    rate_all = url.select('article cars-star-rating')\n",
    "    stars=[i.text[0] for i in rate_all[0::7]]\n",
    "    return stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrap_review(url):\n",
    "    #get review\n",
    "    review = url.select('p.review-card-text')\n",
    "    review=[i.text.rstrip()[2:-2].lstrip() for i in review]\n",
    "    return review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "def scrap_reviewTime(url):\n",
    "    #get review_time\n",
    "    review_time = url.select('p.review-card-review-by')\n",
    "    review_time=[i.text.split('\\n')[-2].lstrip()[3:] for i in review_time]\n",
    "    review_time=[datetime.strptime(i, '%B %d, %Y') for i in review_time]\n",
    "    return review_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrap_reviewArea(url):\n",
    "    #get area\n",
    "    review_city = url.select('p.review-card-review-by')\n",
    "    review_city = [i.text.split('\\n')[-3].lstrip()[5:] for i in review_city]\n",
    "    return review_city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_page(car_soup):\n",
    "    #get tag\n",
    "    links = car_soup.find_all(\"a\", class_=\"cui-button cui-button--secondary\")\n",
    "    #print(links)\n",
    "    page = links[0].get('href')[-7]\n",
    "    #print(page)\n",
    "    if len(links)==1 and page != '2':\n",
    "        # Last Page\n",
    "        return 'This is the last page'\n",
    "    elif len(links)==1 and page == '2':\n",
    "        # The next page of the first page\n",
    "        next_links=links[0].get('href')\n",
    "        next_links='https://www.cars.com'+next_links\n",
    "        return next_links\n",
    "    else:\n",
    "        # Normal next page\n",
    "        next_links=links[1].get('href')\n",
    "        next_links='https://www.cars.com'+next_links\n",
    "        return next_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrap(make, model, year=['2018']):\n",
    "    rate = []\n",
    "    review = []\n",
    "    reviewTime = []\n",
    "    reviewArea = []\n",
    "    for i in year:\n",
    "        url='https://www.cars.com/research/'+make+'-'+model+'-'+i+'/consumer-reviews/'\n",
    "        car_url=requests.get(url)\n",
    "        car_soup = bs4.BeautifulSoup(car_url.text,'lxml')\n",
    "        print('first page '+url)\n",
    "        \n",
    "        rate.extend(scrap_rate(car_soup))\n",
    "        review.extend(scrap_review(car_soup))\n",
    "        reviewTime.extend(scrap_reviewTime(car_soup))\n",
    "        reviewArea.extend(scrap_reviewArea(car_soup))\n",
    "        #print(rate)\n",
    "        next_url = next_page(car_soup)\n",
    "        print('second page '+next_url)\n",
    "        while next_url != 'This is the last page':\n",
    "            print('1 '+next_url)\n",
    "            car_next_url=requests.get(next_url)\n",
    "            car_next_soup = bs4.BeautifulSoup(car_next_url.text,'lxml')\n",
    "            \n",
    "            rate.extend(scrap_rate(car_next_soup))\n",
    "            review.extend(scrap_review(car_next_soup))\n",
    "            reviewTime.extend(scrap_reviewTime(car_next_soup))\n",
    "            reviewArea.extend(scrap_reviewArea(car_next_soup))\n",
    "            \n",
    "            next_url = next_page(car_next_soup)\n",
    "            print('2 '+next_url)\n",
    "    print(len(rate))\n",
    "    outcomes = pd.DataFrame({'Rate':rate,'Review':review, 'Time':reviewTime, 'Area':reviewArea})\n",
    "    return outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
